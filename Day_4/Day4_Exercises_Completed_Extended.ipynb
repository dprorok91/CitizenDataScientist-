{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae78309",
   "metadata": {},
   "source": [
    "## 1. Loading and Exploring Time Series Data\n",
    "We'll use **sktime** datasets for richer time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "import pandas as pd\n",
    "df = load_airline()\n",
    "df = pd.DataFrame(df)\n",
    "df.columns = ['y']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88408297",
   "metadata": {},
   "source": [
    "## 2. Simulating and Handling Missing Data\n",
    "We'll create missing values and explore **multiple imputation methods**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0225ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "m = df.shape[0]\n",
    "mask = np.random.choice([True, False], size=m, p=[0.1,0.9])\n",
    "df_missing = df.copy()\n",
    "df_missing.loc[mask] = np.nan\n",
    "df_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487561a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffill = df_missing.fillna(method='ffill')\n",
    "df_ffill.plot(title='Forward Fill Imputation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad3ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bfill = df_missing.fillna(method='bfill')\n",
    "df_bfill.plot(title='Backward Fill Imputation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interp = df_missing.interpolate()\n",
    "df_interp.plot(title='Interpolation Imputation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d787f01",
   "metadata": {},
   "source": [
    "## 3. Resampling and Aggregation\n",
    "We'll aggregate monthly data to quarterly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5ee443",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_q_sum = df_ffill.resample('Q').sum()\n",
    "df_q_mean = df_ffill.resample('Q').mean()\n",
    "df_q_sum.head(), df_q_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16b3563",
   "metadata": {},
   "source": [
    "## 4. Decomposition\n",
    "Split data into trend, seasonality, residuals using sktime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450d26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.detrend import STLTransformer\n",
    "stl = STLTransformer() \n",
    "df_stl = stl.fit_transform(df_ffill)\n",
    "df_stl.plot(title='STL Decomposition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc2bd0",
   "metadata": {},
   "source": [
    "## 5. Forecasting with sktime Models\n",
    "Fit multiple forecasting models and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "\n",
    "y = df_ffill['y']\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=12)\n",
    "\n",
    "forecaster = NaiveForecaster(strategy='last')\n",
    "forecaster.fit(y_train)\n",
    "y_pred = forecaster.predict(fh=list(range(1,13)))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef223a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "forecaster2 = ExponentialSmoothing(trend='add', seasonal='add', sp=12)\n",
    "forecaster2.fit(y_train)\n",
    "y_pred2 = forecaster2.predict(fh=list(range(1,13)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,6))\n",
    "y_train.plot(label='Train')\n",
    "y_test.plot(label='Test')\n",
    "y_pred.plot(label='Naive Forecast')\n",
    "y_pred2.plot(label='Exponential Smoothing')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa76330d",
   "metadata": {},
   "source": [
    "## 6. Evaluation\n",
    "Compute metrics for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595cf15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.performance_metrics.forecasting import mean_absolute_error, mean_absolute_percentage_error\n",
    "mae_naive = mean_absolute_error(y_test, y_pred)\n",
    "mape_naive = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mae_exp = mean_absolute_error(y_test, y_pred2)\n",
    "mape_exp = mean_absolute_percentage_error(y_test, y_pred2)\n",
    "print('Naive MAE:', mae_naive, 'MAPE:', mape_naive)\n",
    "print('Exp Smoothing MAE:', mae_exp, 'MAPE:', mape_exp)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
